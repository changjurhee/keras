{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니 배치 경사 하강법 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y, \n",
    "                                                            test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, \n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayer:    \n",
    "    def __init__(self, learning_rate=0.1, l1=0, l2=0):\n",
    "        self.w = None              # 가중치\n",
    "        self.b = None              # 절편\n",
    "        self.losses = []           # 훈련 손실\n",
    "        self.val_losses = []       # 검증 손실\n",
    "        self.w_history = []        # 가중치 기록\n",
    "        self.lr = learning_rate    # 학습률\n",
    "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
    "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
    "\n",
    "    def forpass(self, x):\n",
    "        z = np.dot(x, self.w) + self.b        # 선형 출력을 계산합니다. (364,30)(30,1)=>(364,1)+(364,1)\n",
    "        return z\n",
    "\n",
    "    def backprop(self, x, err):              #  x.shape => (364,30) , err => (364,1)\n",
    "        m = len(x)                           # (30,364)(364,1)=>(30,1)\n",
    "        w_grad = np.dot(x.T, err) / m         # 가중치에 대한 그래디언트를 계산합니다.\n",
    "        b_grad = np.sum(err) / m              # 절편에 대한 그래디언트를 계산합니다.\n",
    "        return w_grad, b_grad                 # b 스칼라 => b_grad 스칼라\n",
    "\n",
    "    def activation(self, z):\n",
    "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
    "        a = 1 / (1 + np.exp(-z))              # 시그모이드 계산\n",
    "        return a\n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):  # x.shape => (364,30)\n",
    "#         print(x.shape)\n",
    "#         print(y.shape)\n",
    "        y = y.reshape(-1, 1)                  # 타깃을 열 벡터로 바꿉니다.  y.shape (364,) => y.reshape(-1,1)\n",
    "#         print(y.shape)\n",
    "        \n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        m = len(x)                            # 샘플 개수를 저장합니다.\n",
    "        self.w = np.ones((x.shape[1], 1))     # 가중치를 초기화합니다. w.shape => (30,1)\n",
    "#         print(self.w.shape)\n",
    "        self.b = 0                            # 절편을 초기화합니다.\n",
    "        self.w_history.append(self.w.copy())  # 가중치를 기록합니다.\n",
    "        # epochs만큼 반복합니다.\n",
    "        for i in range(epochs):\n",
    "#             print(x.shape)\n",
    "            z = self.forpass(x)               # 정방향 계산을 수행합니다.  x.shape => (364,30)(30,1)\n",
    "#             print(z.shape)\n",
    "            a = self.activation(z)            # 활성화 함수를 적용합니다.  a.shape => (364,1)\n",
    "#             print(a.shape)\n",
    "            err = a - y                   # 오차를 계산합니다.   y.shape => (364,1)\n",
    "#             print(err.shape)\n",
    "#             print(err)\n",
    "            # 오차를 역전파하여 그래디언트를 계산합니다.\n",
    "            w_grad, b_grad = self.backprop(x, err)  #  x.shape => (364,30) , err => (364,1)\n",
    "#             print(w_grad.shape)\n",
    "#             print(b_grad.shape)\n",
    "            \n",
    "            # 그래디언트에서 페널티 항의 미분 값을 더합니다.\n",
    "            w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m\n",
    "            # 가중치와 절편을 업데이트합니다.\n",
    "            self.w -= self.lr * w_grad\n",
    "            self.b -= self.lr * b_grad\n",
    "            # 가중치를 기록합니다.\n",
    "            self.w_history.append(self.w.copy())\n",
    "            # 안전한 로그 계산을 위해 클리핑합니다.\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
    "            self.losses.append((loss + self.reg_loss()) / m)\n",
    "            # 검증 세트에 대한 손실을 계산합니다.\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)      # 정방향 계산을 수행합니다.\n",
    "        return z > 0             # 스텝 함수를 적용합니다.\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
    "        return np.mean(self.predict(x) == y.reshape(-1, 1))\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        # 가중치에 규제를 적용합니다.\n",
    "        return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
    "    \n",
    "    def update_val_loss(self, x_val, y_val):\n",
    "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
    "        a = self.activation(z)             # 활성화 함수를 적용합니다.\n",
    "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
    "        # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "        val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
    "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualLayer(SingleLayer):\n",
    "    \n",
    "    def __init__(self, units=10, learning_rate=0.1, l1=0, l2=0):\n",
    "        self.units = units         # 은닉층의 뉴런 개수\n",
    "        self.w1 = None             # 은닉층의 가중치\n",
    "        self.b1 = None             # 은닉층의 절편\n",
    "        self.w2 = None             # 출력층의 가중치\n",
    "        self.b2 = None             # 출력층의 절편\n",
    "        self.a1 = None             # 은닉층의 활성화 출력\n",
    "        self.losses = []           # 훈련 손실\n",
    "        self.val_losses = []       # 검증 손실\n",
    "        self.lr = learning_rate    # 학습률\n",
    "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
    "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
    "\n",
    "    def forpass(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1        # 첫 번째 층의 선형 식을 계산합니다\n",
    "        self.a1 = self.activation(z1)            # 활성화 함수를 적용합니다\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 층의 선형 식을 계산합니다.\n",
    "        return z2\n",
    "\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x)       # 샘플 개수\n",
    "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        # 시그모이드 함수까지 그래디언트를 계산합니다.\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "\n",
    "    def init_weights(self, n_features):\n",
    "        self.w1 = np.ones((n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
    "        self.b1 = np.zeros(self.units)               # 은닉층의 크기\n",
    "        self.w2 = np.ones((self.units, 1))           # (은닉층의 크기, 1)\n",
    "        self.b2 = 0\n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        y = y.reshape(-1, 1)          # 타깃을 열 벡터로 바꿉니다.\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        m = len(x)                    # 샘플 개수를 저장합니다.\n",
    "        self.init_weights(x.shape[1]) # 은닉층과 출력층의 가중치를 초기화합니다.\n",
    "        # epochs만큼 반복합니다.\n",
    "        for i in range(epochs):\n",
    "            a = self.training(x, y, m)\n",
    "            # 안전한 로그 계산을 위해 클리핑합니다.\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
    "            self.losses.append((loss + self.reg_loss()) / m)\n",
    "            # 검증 세트에 대한 손실을 계산합니다.\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "            \n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
    "        a = self.activation(z)    # 활성화 함수를 적용합니다.\n",
    "        err = (a - y)            # 오차를 계산합니다.\n",
    "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
    "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
    "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
    "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w1 -= self.lr * w1_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "        return a\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
    "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
    "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomInitNetwork(DualLayer):\n",
    "    \n",
    "    def init_weights(self, n_features):\n",
    "        np.random.seed(42)\n",
    "        self.w1 = np.random.normal(0, 1, \n",
    "                                   (n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
    "        self.b1 = np.zeros(self.units)                        # 은닉층의 크기\n",
    "        self.w2 = np.random.normal(0, 1, \n",
    "                                   (self.units, 1))           # (은닉층의 크기, 1)\n",
    "        self.b2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬의 제너레이터 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo()\n",
      "10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ret' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34180/1703706057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ret' is not defined"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    ret = 10   # 스택\n",
    "    print('foo()')\n",
    "    return ret\n",
    "    print('after')\n",
    "    \n",
    "c = foo()\n",
    "print(c)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object foo at 0x000001DED5F07190>\n",
      "foo()\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    yield 10\n",
    "\n",
    "c = foo()\n",
    "print(c)\n",
    "print(next(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object foo at 0x000001DEC2CF0E40>\n",
      "foo()\n",
      "10\n",
      "after\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    yield 10\n",
    "    print('after')\n",
    "    yield 20\n",
    "\n",
    "c = foo()\n",
    "print(c)\n",
    "n = next(c)\n",
    "print(n)\n",
    "n = next(c)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object foo at 0x000001DED5F07660>\n",
      "foo()\n",
      "10\n",
      "20\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34180/2702758865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    yield 10\n",
    "    yield 20\n",
    "\n",
    "c = foo()\n",
    "print(c)\n",
    "n = next(c)\n",
    "print(n)\n",
    "n = next(c)\n",
    "print(n)\n",
    "n = next(c)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo()\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    yield 10\n",
    "    yield 20\n",
    "\n",
    "for n in foo():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo()\n",
      "(100,)\n",
      "(10,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "foo()\n",
      "(100,)\n",
      "(10,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    a = np.arange(100)\n",
    "    print(a.shape)\n",
    "    return a[0:10]\n",
    "\n",
    "c = foo()\n",
    "print(c.shape)\n",
    "print(c)\n",
    "c = foo()\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(7)\n",
    "b = a[0:10]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo()\n",
      "[100 101 102 103 104 105 106 107 108 109]\n",
      "[110 111 112 113 114 115 116 117 118 119]\n",
      "[120 121 122 123 124 125 126 127 128 129]\n",
      "[130 131 132 133 134 135 136 137 138 139]\n",
      "[140 141 142 143 144 145 146 147 148 149]\n",
      "[150 151 152 153 154 155 156 157 158 159]\n",
      "[160 161 162 163 164 165 166 167 168 169]\n",
      "[170 171 172 173 174 175 176 177 178 179]\n",
      "[180 181 182 183 184 185 186 187 188 189]\n",
      "[190 191 192 193 194 195 196 197 198 199]\n",
      "[200 201 202 203 204]\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "    a = np.arange(100,205)\n",
    "#     print(a)\n",
    "    batch = 10\n",
    "    length = len(a)\n",
    "    bins = length // batch\n",
    "    if length % batch != 0 :\n",
    "        bins += 1\n",
    "    for i in range(bins):\n",
    "        start = batch*i\n",
    "        end = batch*(i+1)\n",
    "        yield a[start:end]\n",
    "\n",
    "# c = foo()\n",
    "# print(c)\n",
    "# n = next(c)\n",
    "# print(n)\n",
    "# n = next(c)\n",
    "# print(n)\n",
    "for n in foo():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니 배치 학습의 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchNetwork(RandomInitNetwork):\n",
    "    \n",
    "    def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
    "        super().__init__(units, learning_rate, l1, l2)\n",
    "        self.batch_size = batch_size     # 배치 크기\n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        y_val = y_val.reshape(-1, 1)     # 타깃을 열 벡터로 바꿉니다.\n",
    "        self.init_weights(x.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
    "        np.random.seed(42)\n",
    "        # epochs만큼 반복합니다.\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\n",
    "                y_batch = y_batch.reshape(-1, 1) # 타깃을 열 벡터로 바꿉니다.\n",
    "                m = len(x_batch)                 # 샘플 개수를 저장합니다.\n",
    "                a = self.training(x_batch, y_batch, m)\n",
    "                # 안전한 로그 계산을 위해 클리핑합니다.\n",
    "                a = np.clip(a, 1e-10, 1-1e-10)\n",
    "                # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "                loss += np.sum(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a)))\n",
    "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
    "            # 검증 세트에 대한 손실을 계산합니다.\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    # 미니배치 제너레이터 함수\n",
    "    def gen_batch(self, x, y):\n",
    "        length = len(x)\n",
    "        bins = length // self.batch_size # 미니배치 횟수\n",
    "        if length % self.batch_size:\n",
    "            bins += 1                    # 나누어 떨어지지 않을 때\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size * i\n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978021978021978"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_net = MinibatchNetwork(l2=0.01, batch_size=32)\n",
    "minibatch_net.fit(x_train_scaled, y_train, \n",
    "                  x_val=x_val_scaled, y_val=y_val, epochs=500)\n",
    "minibatch_net.score(x_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(minibatch_net.losses)\n",
    "plt.plot(minibatch_net.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  케라스를 이용한 미니배치 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7442 - accuracy: 0.6374 - val_loss: 0.7442 - val_accuracy: 0.5824\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.6374 - val_loss: 0.7162 - val_accuracy: 0.5824\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.6374 - val_loss: 0.6896 - val_accuracy: 0.5824\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6374 - val_loss: 0.6664 - val_accuracy: 0.5824\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6374 - val_loss: 0.6440 - val_accuracy: 0.5824\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6374 - val_loss: 0.6234 - val_accuracy: 0.5824\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6429 - val_loss: 0.6041 - val_accuracy: 0.6044\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6538 - val_loss: 0.5870 - val_accuracy: 0.6264\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.6758 - val_loss: 0.5717 - val_accuracy: 0.6374\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.6951 - val_loss: 0.5568 - val_accuracy: 0.6703\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7225 - val_loss: 0.5433 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7582 - val_loss: 0.5302 - val_accuracy: 0.7253\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7802 - val_loss: 0.5181 - val_accuracy: 0.7363\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7912 - val_loss: 0.5063 - val_accuracy: 0.7582\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8159 - val_loss: 0.4953 - val_accuracy: 0.8022\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8187 - val_loss: 0.4845 - val_accuracy: 0.8132\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8352 - val_loss: 0.4748 - val_accuracy: 0.8352\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8544 - val_loss: 0.4655 - val_accuracy: 0.8791\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8571 - val_loss: 0.4564 - val_accuracy: 0.9011\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8599 - val_loss: 0.4481 - val_accuracy: 0.9231\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8626 - val_loss: 0.4405 - val_accuracy: 0.9231\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8681 - val_loss: 0.4330 - val_accuracy: 0.9231\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8791 - val_loss: 0.4257 - val_accuracy: 0.9231\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8874 - val_loss: 0.4188 - val_accuracy: 0.9231\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8956 - val_loss: 0.4121 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.9011 - val_loss: 0.4058 - val_accuracy: 0.9231\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.9038 - val_loss: 0.3998 - val_accuracy: 0.9231\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.9038 - val_loss: 0.3939 - val_accuracy: 0.9231\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.9093 - val_loss: 0.3883 - val_accuracy: 0.9231\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.9093 - val_loss: 0.3828 - val_accuracy: 0.9231\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.9093 - val_loss: 0.3776 - val_accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.9148 - val_loss: 0.3725 - val_accuracy: 0.9231\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.9148 - val_loss: 0.3677 - val_accuracy: 0.9231\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.9176 - val_loss: 0.3630 - val_accuracy: 0.9231\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.9176 - val_loss: 0.3585 - val_accuracy: 0.9231\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.9176 - val_loss: 0.3540 - val_accuracy: 0.9231\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.9203 - val_loss: 0.3499 - val_accuracy: 0.9341\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.9231 - val_loss: 0.3459 - val_accuracy: 0.9341\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.9258 - val_loss: 0.3420 - val_accuracy: 0.9341\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.9286 - val_loss: 0.3383 - val_accuracy: 0.9341\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.9286 - val_loss: 0.3347 - val_accuracy: 0.9341\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.9313 - val_loss: 0.3313 - val_accuracy: 0.9341\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.9313 - val_loss: 0.3279 - val_accuracy: 0.9341\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9313 - val_loss: 0.3246 - val_accuracy: 0.9341\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.9313 - val_loss: 0.3214 - val_accuracy: 0.9341\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.9313 - val_loss: 0.3183 - val_accuracy: 0.9341\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.9368 - val_loss: 0.3154 - val_accuracy: 0.9341\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.9396 - val_loss: 0.3126 - val_accuracy: 0.9341\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.9423 - val_loss: 0.3098 - val_accuracy: 0.9341\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.9423 - val_loss: 0.3071 - val_accuracy: 0.9341\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.9451 - val_loss: 0.3044 - val_accuracy: 0.9341\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9451 - val_loss: 0.3018 - val_accuracy: 0.9341\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.9451 - val_loss: 0.2994 - val_accuracy: 0.9341\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.9451 - val_loss: 0.2970 - val_accuracy: 0.9341\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.9451 - val_loss: 0.2947 - val_accuracy: 0.9341\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9451 - val_loss: 0.2924 - val_accuracy: 0.9341\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9451 - val_loss: 0.2902 - val_accuracy: 0.9341\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9451 - val_loss: 0.2880 - val_accuracy: 0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9478 - val_loss: 0.2859 - val_accuracy: 0.9341\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.9451 - val_loss: 0.2839 - val_accuracy: 0.9341\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.9478 - val_loss: 0.2819 - val_accuracy: 0.9341\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.9478 - val_loss: 0.2799 - val_accuracy: 0.9341\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.9478 - val_loss: 0.2780 - val_accuracy: 0.9341\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.9478 - val_loss: 0.2761 - val_accuracy: 0.9341\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9478 - val_loss: 0.2743 - val_accuracy: 0.9341\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.9478 - val_loss: 0.2725 - val_accuracy: 0.9341\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9478 - val_loss: 0.2708 - val_accuracy: 0.9451\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.9478 - val_loss: 0.2691 - val_accuracy: 0.9451\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.9478 - val_loss: 0.2675 - val_accuracy: 0.9451\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9478 - val_loss: 0.2659 - val_accuracy: 0.9451\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9478 - val_loss: 0.2643 - val_accuracy: 0.9560\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9478 - val_loss: 0.2627 - val_accuracy: 0.9560\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9478 - val_loss: 0.2612 - val_accuracy: 0.9560\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9505 - val_loss: 0.2597 - val_accuracy: 0.9560\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9505 - val_loss: 0.2583 - val_accuracy: 0.9560\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9505 - val_loss: 0.2569 - val_accuracy: 0.9560\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9505 - val_loss: 0.2555 - val_accuracy: 0.9560\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9505 - val_loss: 0.2542 - val_accuracy: 0.9560\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.9505 - val_loss: 0.2528 - val_accuracy: 0.9560\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9505 - val_loss: 0.2515 - val_accuracy: 0.9560\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9505 - val_loss: 0.2503 - val_accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9505 - val_loss: 0.2491 - val_accuracy: 0.9560\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9533 - val_loss: 0.2479 - val_accuracy: 0.9560\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9505 - val_loss: 0.2467 - val_accuracy: 0.9560\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9505 - val_loss: 0.2455 - val_accuracy: 0.9560\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9505 - val_loss: 0.2444 - val_accuracy: 0.9560\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9505 - val_loss: 0.2433 - val_accuracy: 0.9560\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9505 - val_loss: 0.2422 - val_accuracy: 0.9560\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9505 - val_loss: 0.2411 - val_accuracy: 0.9560\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9505 - val_loss: 0.2401 - val_accuracy: 0.9560\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9505 - val_loss: 0.2390 - val_accuracy: 0.9560\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9505 - val_loss: 0.2380 - val_accuracy: 0.9560\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9505 - val_loss: 0.2370 - val_accuracy: 0.9560\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9505 - val_loss: 0.2360 - val_accuracy: 0.9560\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9505 - val_loss: 0.2350 - val_accuracy: 0.9560\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9505 - val_loss: 0.2341 - val_accuracy: 0.9560\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9505 - val_loss: 0.2332 - val_accuracy: 0.9560\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9505 - val_loss: 0.2322 - val_accuracy: 0.9560\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9505 - val_loss: 0.2314 - val_accuracy: 0.9560\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9505 - val_loss: 0.2305 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAszElEQVR4nO3deXhU9fn+8fcz2TeSkASyAmGXNWhYBEHckEXFhU1URKuUqtVasWKrXay2frvY1l+p1NaqdQMLotQFVMQFUSHBsO9rwhoCCQTIOs/vj5lihABBZnKSzPO6rnOROXPmzP1hmZtz5iyiqhhjjAlcLqcDGGOMcZYVgTHGBDgrAmOMCXBWBMYYE+CsCIwxJsAFOx3gbCUmJmqbNm2cjmGMMY1Kbm7uflVNqu25RlcEbdq0IScnx+kYxhjTqIjI9lM9Z7uGjDEmwFkRGGNMgLMiMMaYANfoviMwxjQ9lZWVFBQUUFZW5nSURi88PJz09HRCQkLq/BorAmOM4woKCoiJiaFNmzaIiNNxGi1VpaioiIKCAjIzM+v8Ots1ZIxxXFlZGQkJCVYC50hESEhIOOstKysCY0yDYCXgG9/l9zFgimDHuhyWTP8+5WVHnI5ijDENSsAUwYGdm+mzZwabln7gdBRjjGlQAqYIOvQdRrmGcGT1e05HMcY0MMXFxfztb38769cNHz6c4uLis37dxIkTmTVr1lm/zl8CpgiiopuxNrwHyfsWOR3FGNPAnKoIqqurT/u6d999l7i4OD+lqj8Bdfjo4fTBZG3+I0UFG0hI7+h0HGNMLX7139Ws2XXIp+vsktqMX1zd9ZTPT506lc2bN5OVlUVISAjR0dGkpKSQl5fHmjVruPbaa8nPz6esrIz77ruPSZMmAd9c+6y0tJRhw4Zx0UUXsXjxYtLS0njrrbeIiIg4Y7YFCxYwZcoUqqqq6N27N8888wxhYWFMnTqVuXPnEhwczJAhQ/jDH/7Af/7zH371q18RFBREbGwsn376qU9+fwJmiwCg5flXA5C/5C2HkxhjGpInn3ySdu3akZeXx+9//3uWLFnCE088wZo1awD417/+RW5uLjk5OTz99NMUFRWdtI6NGzdy9913s3r1auLi4pg9e/YZ37esrIyJEycyc+ZMVq5cSVVVFc888wwHDhxgzpw5rF69mhUrVvDII48A8NhjjzF//nyWL1/O3LlzfTb+gNoiaN+5JwW0JGTLAuBBp+MYY2pxuv+515c+ffp864Ssp59+mjlz5gCQn5/Pxo0bSUhI+NZrMjMzycrKAuCCCy5g27ZtZ3yf9evXk5mZSceOnj0Ut956K9OmTeOee+4hPDycO+64gxEjRnDVVVcBMGDAACZOnMiYMWO4/vrrfTBSj4DaInAFudgSdyFtS5fhrjjmdBxjTAMVFRV1/OePP/6YDz/8kC+++ILly5fTq1evWk/YCgsLO/5zUFAQVVVVZ3wfVa11fnBwMEuWLOGGG27gzTffZOjQoQBMnz6dxx9/nPz8fLKysmrdMvkuAqoIAFwdhxBBOfl5C5yOYoxpIGJiYjh8+HCtz5WUlBAfH09kZCTr1q3jyy+/9Nn7du7cmW3btrFp0yYAXnrpJS6++GJKS0spKSlh+PDh/PnPfyYvLw+AzZs307dvXx577DESExPJz8/3SY6A2jUE3sNIvwqheMW7tO5zldNxjDENQEJCAgMGDKBbt25ERETQsmXL488NHTqU6dOn06NHDzp16kS/fv189r7h4eE8//zzjB49+viXxZMnT+bAgQOMHDmSsrIyVJU//elPADz44INs3LgRVeWyyy6jZ8+ePskhp9o0aaiys7P1XO9Qlvv4YJLZT9ojq3yUyhhzLtauXct5553ndIwmo7bfTxHJVdXs2pYPuF1DAEUpg0iryufYvi1ORzHGGMcFZBE0z/LsEtrx5RsOJzHGNGV33303WVlZ35qef/55p2OdJOC+IwDo0TObrXNTkA3zgClOxzHGNFHTpk1zOkKdBOQWQWiwiy3NB9Km9Guqj/n2DEZjjGls/FoEIjJURNaLyCYRmVrL8w+KSJ53WiUi1SLS3J+Z/ie82whCqWLbkv/Wx9sZY0yD5bciEJEgYBowDOgC3CgiXWouo6q/V9UsVc0CHgY+UdUD/spUU/cLr6RYoziy8u36eDtjjGmw/LlF0AfYpKpbVLUCmAGMPM3yNwKv+THPtzSLjGBNVB9a7V+EVp/5DEBjjGmq/FkEaUDN094KvPNOIiKRwFCg1qs0icgkEckRkZzCwkKfBaxufyVxHGLnqs98tk5jTGCIjo4+5XPbtm2jW7du9Zjm3PizCGq7ceapzl67Gvj8VLuFVPVZVc1W1eykpCSfBeww4DoqNYh9uW/6bJ3GGNPY+PPw0QIgo8bjdGDXKZYdRz3uFvqf5JbJrAjtSsLOhfX91saYU3lvKuxZ6dt1JneHYU+edpGHHnqI1q1bc9dddwHwy1/+EhHh008/5eDBg1RWVvL4448zcuTp9nCfrKysjB/84Afk5OQQHBzMU089xSWXXMLq1au57bbbqKiowO12M3v2bFJTUxkzZgwFBQVUV1fz6KOPMnbs2O887Lry5xbBUqCDiGSKSCieD/uTLqAtIrHAxYAjNwk4lHEprau3U5i/3om3N8Y0EOPGjWPmzJnHH7/++uvcdtttzJkzh2XLlrFw4UIeeOCBU14x9FT+dy7BypUree2117j11lspKytj+vTp3HfffeTl5ZGTk0N6ejrz5s0jNTWV5cuXs2rVquNXHfU3v20RqGqViNwDzAeCgH+p6moRmex9frp30euA91X1iL+ynE5av1Gw5c/sWDSDpBt/4UQEY0xNZ/ifu7/06tWLffv2sWvXLgoLC4mPjyclJYX777+fTz/9FJfLxc6dO9m7dy/Jycl1Xu+iRYv44Q9/CHiuNtq6dWs2bNjAhRdeyBNPPEFBQQHXX389HTp0oHv37kyZMoWHHnqIq666ioEDB/pruN/i1/MIVPVdVe2oqu1U9QnvvOk1SgBVfUFVx/kzx+m06dCN9a52xG2xw0iNCXSjRo1i1qxZzJw5k3HjxvHKK69QWFhIbm4ueXl5tGzZstZ7EZzOqbYgxo8fz9y5c4mIiODKK6/ko48+omPHjuTm5tK9e3cefvhhHnvsMV8M64wC8szimkSEXRkjaFe5geKCdU7HMcY4aNy4ccyYMYNZs2YxatQoSkpKaNGiBSEhISxcuJDt27ef9ToHDRrEK6+8AsCGDRvYsWMHnTp1YsuWLbRt25Z7772Xa665hhUrVrBr1y4iIyO5+eabmTJlCsuWLfP1EGsV8EUAkNp/PAA7Pn3Z4STGGCd17dqVw4cPk5aWRkpKCjfddBM5OTlkZ2fzyiuv0Llz57Ne51133UV1dTXdu3dn7NixvPDCC4SFhTFz5ky6detGVlYW69atY8KECaxcuZI+ffqQlZXFE088cfxexf4WkPcjOJGqsuLXF9I86BgZP1vu03UbY87M7kfgW3Y/gu9ARNiTMYKMym0c3r7C6TjGGFOvrAi8UvuPpVqFgkUvOR3FGNNIrFy58qT7DfTt29fpWGctIO9HUJuuHTqw1NWDzK1vg/4OpLYTo40x/qKqSCP7d9e9e/fjN5ZvKL7L7n7bIvByuYQ9rUbQomoXR7ctdTqOMQElPDycoqKi7/QhZr6hqhQVFREeHn5Wr7MtghrSLxxD+bbfsWvRy7TP7ON0HGMCRnp6OgUFBfjyopKBKjw8nPT09LN6jRVBDb06tuGzoPPpue2/4P4TuIKcjmRMQAgJCSEzM9PpGAHLdg3V4HIJRe2uJa76AIfWfOh0HGOMqRdWBCfoMmg0hzSSfYvt5DJjTGCwIjhB54wWfBE2gNTdH0DFUafjGGOM31kR1KK8yw1E6jEK7YY1xpgAYEVQi+xBV7Nbm3N46atORzHGGL+zIqhFavNocqIvodWBxeiR/U7HMcYYv7IiOIXQXuMIppqdi2yrwBjTtFkRnEK//oNZp62QPDt6yBjTtFkRnEJsZCirWo4k7dh6ygvs0tTGmKbLiuA00gfdSrkGs/OjZ52OYowxfmNFcBp9urTns6B+tNj6FlSe3X1KjTGmsbAiOA2XSzh03jii9TD7c99wOo4xxviFFcEZ9LnsOgo0kSNfPu90FGOM8QsrgjNIbx7NkthhtC5egvvANqfjGGOMz1kR1EGzCyfiVqHgo384HcUYY3zOiqAOLsruxeeSRezaV6G60uk4xhjjU1YEdRAeEsSujjcTW32Ag8vmOB3HGGN8yoqgji68Yiz5mkTpZ9OdjmKMMT5lRVBHrZJi+DL+GjIO5VKxe43TcYwxxmesCM5CyuA7PWcaf/BXp6MYY4zPWBGchf49OrMw+CJabp0D5aVOxzHGGJ/waxGIyFARWS8im0Rk6imWGSwieSKyWkQ+8Weec+VyCWVZE4nUo+xZ9KLTcYwxxif8VgQiEgRMA4YBXYAbRaTLCcvEAX8DrlHVrsBof+XxlcGXDmeVtsW1ZDq4q52OY4wx58yfWwR9gE2qukVVK4AZwMgTlhkPvKGqOwBUdZ8f8/hEXFQYK1rfSovyHRzOe9PpOMYYc878WQRpQH6NxwXeeTV1BOJF5GMRyRWRCbWtSEQmiUiOiOQUFhb6KW7d9Rk+kW3ulhz56I+g6nQcY4w5J/4sAqll3omfmsHABcAI4ErgURHpeNKLVJ9V1WxVzU5KSvJ90rPUPjmOTxLHkVy6mopNDfprDWOMOSN/FkEBkFHjcTqwq5Zl5qnqEVXdD3wK9PRjJp/peOX3KdRYiub/n9NRjDHmnPizCJYCHUQkU0RCgXHA3BOWeQsYKCLBIhIJ9AXW+jGTz/TrmMrbkdeSsn8xuivP6TjGGPOd+a0IVLUKuAeYj+fD/XVVXS0ik0VksneZtcA8YAWwBPinqq7yVyZfEhESB0/msEZQ+N5vnY5jjDHfmWgj+7IzOztbc3JynI4BQEWVm5d/cye3u2fB9z+FlEaxV8sYE4BEJFdVs2t7zs4sPgehwS5CBt5LiUZS/M4vnY5jjDHfiRXBORo1oBsvBV1LXMFHkL/E6TjGGHPWrAjOUURoEJED76ZQm3H4nUftvAJjTKNjReADY/t35nnXDcTs+RK2fOx0HGOMOStWBD4QFRZMs4GT2KkJHH3vF7ZVYIxpVKwIfOTmAR151jWWyP3LYe2Jp0sYY0zDZUXgI9FhwSQPmsh6dzpl835hN7k3xjQaVgQ+NHFAe54NuZnwQ1vRZS85HccYY+rEisCHIkKDyLr8Rpa6O1Kx4LdQccTpSMYYc0ZWBD42rk8rXoi8jbCyfbi/+JvTcYwx5oysCHwsJMjFkKEj+aD6AtyfPQWH9zgdyRhjTsuKwA+u7pHKjPhJuKsqqJ7/qNNxjDHmtKwI/MDlEiZefRnPVo0gaNXrsP0LpyMZY8wpWRH4ycAOSazI/B57SKDq7QfsRvfGmAbLisCPHrzqfB6vvJngwtWQ8y+n4xhjTK2sCPyoQ8sY4rJHsdjdleoFv4bSQqcjGWPMSawI/OxHV3TiSfkeWn4EPvyF03GMMeYkVgR+lhgdxlWXDebvVcMh7xXYvtjpSMYY8y1WBPXgtgGZvBd/C7tJwv3f++06RMaYBsWKoB6EBLl49LoLeLRiAq796+DLZ5yOZIwxx1kR1JO+bRNolnUNC9zn4174Gzi4zelIxhgDWBHUq58OP4//c91BWbWgc++1G9gYYxoEK4J6lBgdxq3DLuLxihuRrZ/AshedjmSMMVYE9e3G3q3YnHEDX9EV9/yfQUmB05GMMQHOiqCeuVzCb2/oyU+rJlFZWYX+90e2i8gY4ygrAge0TYpm9BUD+W3FGGTTB57zC4wxxiFWBA6546JMlrUcTS5dcL/3EBTvcDqSMSZAWRE4JDjIxe/GZDGl8vtUVFajb90DbrfTsYwxAciKwEGdk5sx5oqB/KpivOcoopznnI5kjAlAfi0CERkqIutFZJOITK3l+cEiUiIied7p5/7M0xBNGtSWDWk3sIieuN9/FPZvcjqSMSbA+K0IRCQImAYMA7oAN4pIl1oW/UxVs7zTY/7K01AFuYSnxmbxiHsyR9zB6Ozboarc6VjGmABSpyIQkftEpJl4PCciy0RkyBle1gfYpKpbVLUCmAGMPNfATVHrhCjuHDGAH5fdiexeDgsCrg+NMQ6q6xbB7ap6CBgCJAG3AU+e4TVpQH6NxwXeeSe6UESWi8h7ItK1thWJyCQRyRGRnMLCpnlzl/F9WiGdR/By9RXwxV9h04dORzLGBIi6FoF4fx0OPK+qy2vMO9NrajrxzKllQGtV7Qn8P+DN2lakqs+qaraqZiclJdUxcuMiIvxuVA/+GXE7W1yt0TcmQ+k+p2MZYwJAXYsgV0Tex1ME80UkBjjTsY4FQEaNx+nArpoLqOohVS31/vwuECIiiXXM1OTERYby5Li+3FV2F1XHSuCNO+2m98YYv6trEXwPmAr0VtWjQAie3UOnsxToICKZIhIKjAPm1lxARJJFRLw/9/HmKTqL/E1Ov7YJDLnkUh6puBW2fAyfPeV0JGNME1fXIrgQWK+qxSJyM/AIUHK6F6hqFXAPMB9YC7yuqqtFZLKITPYuNgpYJSLLgaeBcap24Z17L23PjlY38F/3APTj38C2z52OZIxpwqQun7sisgLoCfQAXgKeA65X1Yv9G+9k2dnZmpOTU99vW+/2l5Yz5i8f8GLVFNKiFNfkRRDdNL8fMcb4n4jkqmp2bc/VdYugyvs/9ZHAX1T1L0CMrwKakyVGh/GHWwZwd8W9VB05gL5+C1RVOB3LGNME1bUIDovIw8AtwDvek8VC/BfLAJzfKp7RV49gSvkkZMcX8O4DdslqY4zP1bUIxgLleM4n2IPnfIDf+y2VOe7mvq0IyRrDtKprYNm/YcmzTkcyxjQxdSoC74f/K0CsiFwFlKnqv/2azACe8wueuK4b81rcwULNRuc9DJs/cjqWMaYJqeslJsYAS4DRwBjgKxEZ5c9g5hvhIUE8c0tvHg26j62Sjr4+AfatczqWMaaJqOuuoZ/hOYfgVlWdgOc6Qo/6L5Y5UXp8JL8b358JZVMoqQpBXx1tZx4bY3yirkXgUtWanzpFZ/Fa4yP92ycy+ZqLmXD0fipL9qIzxkPlMadjGWMaubp+mM8TkfkiMlFEJgLvAO/6L5Y5lZv7tebCgVfww/IfQEEOvDHJ7mxmjDkndf2y+EHgWTwnlPUEnlXVh/wZzJzaQ0M7E9T1Gp6oGg9r58L7jzgdyRjTiAXXdUFVnQ3M9mMWU0cul/DUmCxu+sdN/Ht3ERO+nAZxGdDvB05HM8Y0QqfdIhCRwyJyqJbpsIgcqq+Q5mThIUE8N7E3r8R9nw+1j+ew0tVznI5ljGmETlsEqhqjqs1qmWJUtVl9hTS1i4sM5YU7LuTxsPtZTid09h2wYb7TsYwxjYwd+dPIpcRG8M87BnKPTGUdbdCZt8DmhU7HMsY0IlYETUD7FjH89fZL+F7Vw2zRFPS1G+3S1caYOrMiaCKyMuL4w62DuaniYQo0AX35BrvvsTGmTqwImpD+7RJ5fPwl3HDsEbaRir46Dta85XQsY0wDZ0XQxFzepSWPjr2Ya49MZUNQe/Q/EyHvVadjGWMasDqfR2Aaj6t7puLWAdwwM4jXYp6m+5s/gPJS6DvJ6WjGmAbIiqCJGpmVBvRj9EwXLzX7O73fexDKD8HAB0DE6XjGmAbEiqAJG5mVRpCrLxNmBjEtMoxLP/o1lJXAFY9ZGRhjjrMiaOKu6pFKXER/Jr8UzGMh4Vy/+Gk4dgCu+gsE2R+/McaKICBc1CGRVyf157Z/BbNfYpj09ctw9CCMeg5CIpyOZ4xxmB01FCB6pMcx664BvBQxnsfdE2H9O/DS9XD0gNPRjDEOsyIIIJmJUcz+QX8WJ4zi3qp7qS5YCs9dAUWbnY5mjHGQFUGAaRETzszv92N/6xGMPfYwx0oK0eeugB1fOR3NGOMQK4IAFBMewgu39aFV1mUMO/Jz9leFoy9eDStedzqaMcYBVgQBKjTYxR/H9GTkpYO44tDPWRvUCd64ExY8Zre+NCbA2FFDAUxEuP+KjmQ0j2T0G1E8GfEiV3/2RyhcD9dNh7AYpyMaY+qBFYFh1AXpZCZG8v1/h7GGVH6y/mXkH5fBuFcgsYPT8Ywxfma7hgwAF7Ruzls/HMjH8aMZXz6VoyX70GcvgbVvOx3NGONnfi0CERkqIutFZJOITD3Ncr1FpFpERvkzjzm9tLgIZv/gQpJ7DuGyw4+xlVSYeRPM/xlUVzodzxjjJ34rAhEJAqYBw4AuwI0i0uUUy/0fYDfbbQAiQ4N5akxP7rr2Yq4+8lNmBw2DL/4Kzw+D4h1OxzPG+IE/twj6AJtUdYuqVgAzgJG1LPdDYDawz49ZzFkQEW7p15qXv38xT4VM4odV91Gxew06fSCse8fpeMYYH/NnEaQB+TUeF3jnHSciacB1wPTTrUhEJolIjojkFBYW+jyoqV2vVvG8c+9FHOtwDZcffZwd7iSYMR7emwpV5U7HM8b4iD+LoLbrHOsJj/8MPKSq1adbkao+q6rZqpqdlJTkq3ymDuIiQ/nHhAuYMHwww488ykzXCPjqGXhuCOzf5HQ8Y4wP+PPw0QIgo8bjdGDXCctkAzPEc238RGC4iFSp6pt+zGXOkohwx8C29GubwL2vxbLgYEf+su85wv8+EBnyOGTfbvc3MKYR8+cWwVKgg4hkikgoMA6YW3MBVc1U1Taq2gaYBdxlJdBwdUuL5e17LyLhgusZfOQ3fK2d4J0fw6tj4fAep+MZY74jvxWBqlYB9+A5Gmgt8LqqrhaRySIy2V/va/wrMjSY317fg8cnDGGS+2F+XT2Rqs0fo3/rB6tmOx3PGPMdiOqJu+0btuzsbM3JyXE6hgH2l5YzdfZKtq5bxvTof9Khcj10uRZG/BGiEp2OZ4ypQURyVTW7tufszGLznSVGh/GPCRcw+YZhjKn8JU9Vj6V67dvotL6weo7T8YwxdWRFYM6JiDA6O4N5P76UNe3vZHjZ42yuiIP/TISZt8DhvU5HNMacgRWB8YmWzcL5x4Rs7hp7DTe6n+AP1WOpWvceOq035L5ol7Y2pgGzIjA+IyKMzEpj/gOXsrPbXVxZ9htWVKTDf++FF6/yXN7aGNPgWBEYn2seFcqfxmbx89uu496wX/OTyjs5mr8CfaY/vP8olJc6HdEYU4MVgfGbizsmMf/Hg2kx6E4uKf8Db7gHweKn0b/29hxq2siOWDOmqbIiMH4VHhLElCs78cp9VzEnfSrXl/+SzUfDYdbt8OLVsHeN0xGNCXhWBKZetG8RzUvf68Okm8ZxW/Dv+Fnl7ZTuyEOnXwTv/gSOHnA6ojEBy4rA1BsRYWi3FD6YcilpV9zNldV/5tWqS3Av+Qfuv2TBF9OgqsLpmMYEHCsCU+/CQ4K4a3B75j54Neuzf8WIyidZXNYa5v8U97S+sGaufX9gTD2yS0wYx20pLOX389dzdM18fh76Ku3Ix53RD9eVT0B6rWfEG2PO0ukuMWFFYBqM3O0H+eO81bTe8QYPhsyiOSW4Ow7DdekjkNzN6XjGNGpWBKbRUFU+31TEX+d9TfaemUwOeZcojkLX65CLH4IWnZ2OaEyjZEVgGh1V5YM1e3l2/jIGH5jB94LnE0452vU6XFYIxpw1KwLTaLndytsrd/PSh7lccvB1Jga/TwTluM+7hqCLf2K7jIypIysC0+i53cpH6/bx0ke59N4zg4nB7xPNMao6DCV40AOQ0cfpiMY0aFYEpslQVb7ccoAXPvqaztte5faQecRyhIq0foQOuh86DAGXHRVtzImsCEyTtDy/mBc+XkX8+hl8L+g90mQ/5XHtCbvoHug5DkIinI5oTINhRWCatO1FR3jhs40cXjaLCbxND9dWKkLjCe59G64+d0BsmtMRjXGcFYEJCCVHK3l96Q6Wf/4O1xx7k8uCvkYQKjqOIHzAXdCqH4g4HdMYR1gRmIBS7VYWrN3LvM+X0HHHTG4MWkisHOFIfBciB96FdB9lu41MwLEiMAFr6/4jvP75Osq/nsEY93t0duVTHtwMssYT1u9OSGzvdERj6oUVgQl4xyqq+e/yneR99jb9D77Fla6lhEg1Jcn9aTbgDuS8qyE41OmYxviNFYExNazaWcLbi78mctVrXM+HpMt+jobEoz1uJKrfbZDU0emIxvicFYExtThaUcV7K3axbvFbXFD4Fpe5lhEi1exv3ouYvhMI63EdRMQ7HdMYn7AiMOYMtu0/wvyvVlCd9ypXln9AO9duKiWEg6kXE9/vFkI6D4WQcKdjGvOdWREYU0eqytKtB8j54iOabZzDEP2cFlLMMVc0BzOH06L/LQRnXmRnL5tGx4rAmO+gosrN5xt2s/7Ld0ndPpfL+IooKackOJGStleRfNHNhGZk27kJplGwIjDmHJVXVbNozQ52fjWH9J3vMEDzCJMq9oekUtJ2BGkDbiI8I8tKwTRYjhWBiAwF/gIEAf9U1SdPeH4k8GvADVQBP1LVRadbpxWBcVpFlZuv1mxm91ezSNv5Hn11JcHiZm9wGgdaDyWl/43EtbUtBdOwOFIEIhIEbACuAAqApcCNqrqmxjLRwBFVVRHpAbyuqqe944gVgWlIqqrdLFu7id1fzSKlYB7nuz2lsC+oJXvShtCiz2iSuwy07xSM405XBMF+fN8+wCZV3eINMQMYCRwvAlUtrbF8FNC49lOZgBcc5KJPt47Q7aeoPsy6LdvY8cVs4re9R9b2Vwnd8RIHJI4diYMI734N7foMJyQ8yunYxnyLP4sgDciv8bgA6HviQiJyHfBboAUworYVicgkYBJAq1atfB7UGF8QEc5rl8l57aYAU8jftYfNi98gbPM8uu/7gOiP5nJsQShroi6gvO0QWvUdSXJGO6djG+PXXUOjgStV9Q7v41uAPqr6w1MsPwj4uapefrr12q4h0xgdLi1l3ZfvUbn2XTKLPiOFQgC2uFqzK2kgUV2H0qn35URG2MXwjH84tWuoAMio8Tgd2HWqhVX1UxFpJyKJqrrfj7mMqXcx0dH0vnw0XD4adbvZti6XvcveJib/Y/rueY2QvS9TuiCCpRG9KE0fRFKvEXTu3I3gIPtuwfifP4tgKdBBRDKBncA4YHzNBUSkPbDZ+2Xx+UAoUOTHTMY4Tlwu2nTpTZsuvQEoKz3IxiXvUbb2fVoVLaLlpsWw6Um2aQqbm/Whuu1ltLpgCB3Tk3G57Egk43t+KwJVrRKRe4D5eA4f/ZeqrhaRyd7npwM3ABNEpBI4BozVxnZigzHnKDw6ni6XjodLx4MqB3esZmfuOwRvXUj/w/OIWP4WFXlBfC2d2N28D8EdBtO25yDaJze3YjA+YSeUGdOQVZVTtPYT9ue9S+TOxaSVbcCFclTDyJPO7IzLRjIHktm9P91aJRIWHOR0YtNA2ZnFxjQRevQghasWULJ2ITG7F5NctgWAIxrGMu1EQez5uFsPIO28/vTKbElsZIjDiU1DYUVgTFNVWsjhDZ9wYM1CInYupsUxTzEc01CWuTuwOaI7Zal9ie/Ynx5t0+jQItp2JwUoKwJjAsWRIsq3fMaBVQsILviShCMbcaFUahCrtQ3L5TwOJp5PaJsL6diuHT0z4kiKCXM6takHVgTGBKqyEnTHVxSv/5SqrYuJO7iSEK0AYJu7JbnakS1hXahMOZ+Etr3onpFA17RYYiNsl1JTY0VgjPGoKofdy6ncupjSjYsI35NLROUBwLM7aYW25Wt3e3ZFdcGdmk1a6/Z0S2tG19RYmkfZPZ0bMysCY0ztVKF4BxQspWzbV1RsW0LUgdUEaSUAezSe5e52LHe3pSCiM5rSizYZaXRN9ZRDenwEYldZbRSsCIwxdVdVDntWws5cKrYvoTp/KRGHtx9/eru2YKW7LSvdmWwJbkdVy+6kp6bTKTmGzskxdEyOoVm47VpqaKwIjDHn5thB2JUHu5ZRvfNrqgq+Jqy04PjTuzSRle42rHK3YZVmciCmM4nJreic2oyOLWPo2DKGtklRdp6Dg6wIjDG+d/QA7FkBu5eju5dTVZBHSPHm408XSywrq1uz2t2aNe7WrKUN2rwtHZLj6NAyhk4tY+jYMpo2iVGE2DWV/M6KwBhTP8oOwd5Vnl1Le1bg3r0C9q3D5fYcqVQhYWyWVqyoTGOdO4P1msFmaUVsYiptE6Np1yKKdknRnqlFNNFh/rwcWmCxIjDGOKeqAvavh90rYO9q2LsK3bsKOfrN9SUPueLYLBmsqEhlnTud9e4MNmo6kc3iaZMQRWZiFG0So2ifFE2HltGkx0cSZCfGnRWnLkNtjDEQHArJ3T2Tl6jCkULYtwb2rqHZvjX02reWrH2LkMojx5crdiexrSiD1XtSWFmRwgfuNDZqGmXBzWjVPJLWzSNpnRBFZmIkmYnRtEmMJDU2ws6ePktWBMaY+icC0S08U9vB38x2u6EkH/athX1riCtcR1bhOrL2LwQ9eny50pAEdlaks3lXMiu2tGRBVTKbNYWdmkRwcDAZ8RG0SYgio3kkGc0jaVVjigi1L6xPZLuGjDENn9sNJTugcAMUroPC9VC00fNrWfHxxapdoRSFZVDgSmVDVTIrjiWxrrIFWzSFYmIAaBETRuuEbwoiIz6SVgmeX1vEhDXZrQn7jsAY0zSpwtEi2L/RUwz7N8D+TZ6fD24Dd9XxRStCmnEwLJ2dQalsrm7JqrJElh9NYKs7mRKiAQgNcpEWH0FaXATp8Z4po3kkaXERpMVH0CImvNF+N2FFYIwJPNWVnrOmizZ5iuLAFjiwGYq2eHY/8c1nX2VIMw5FpLM3OIV8WrKxIpGVR5uz4mgCe4hH8RzeGuwSUuLCSY2NOF4Yqd4pLS6clNgIohrokU5WBMYYU1NlmWeL4cBmOLAVDm795tfiHd/aknAHhVEWmUZxWAp7g5LZ4U5iU2VzVh6JJ680lmKNAr7ZSoiNCPGUQ2w4qXERx4sjJdZTFC1jwxw5sc6OGjLGmJpCwqFFZ890ouoqOFRwvBhcB7YSeXAbkcXbST24gF41vpMgDNyhMZRFpVMSlsK+4GQKNInNlc1Ztz+Oj7bFsLMsjJpFAZAYHUpybDjJzSJIjg0juVk4LWtMyc3CaRYRXG/XcbIiMMaYmoKCIb6NZ+KSk58/VgzF2+Hgdijejqs4n8jiHUQWbydl71f0rHH4K4DGxlARnU5pRBpFISnsJYEd1c3ZVB7H+qJY3tkWzsFj1Se9TXiI64SCCGNghyQGdUzy+ZCtCIwx5mxExHmmlJ4nP/e/L6+Lt0NxPpTkI8U7CCveQdjB7STs/YKOJxQFrhDcyWlURKVQGtaSg8Et2CcJ7KyOZ0tFMzYfi2VFfhh7DlcQERJkRWCMMQ2aCEQleqa0C05+XtVzuGtJwbcmV0k+4SU7CS/KJfHQLjroCVsIrhA0IQV31CSgk89jWxEYY0x9EYGIeM9U40zrb3FXe866PrTLMx3eDYd2Iod2ERST7JdYVgTGGNOQuIIgJtkzpZ1fP29ZL+9ijDGmwbIiMMaYAGdFYIwxAc6KwBhjApwVgTHGBDgrAmOMCXBWBMYYE+CsCIwxJsA1ustQi0ghsP07vjwR2O/DOI1FII47EMcMgTnuQBwznP24W6tqrRcqanRFcC5EJOdU1+NuygJx3IE4ZgjMcQfimMG347ZdQ8YYE+CsCIwxJsAFWhE863QAhwTiuANxzBCY4w7EMYMPxx1Q3xEYY4w5WaBtERhjjDmBFYExxgS4gCkCERkqIutFZJOITHU6jz+ISIaILBSRtSKyWkTu885vLiIfiMhG76/xTmf1NREJEpGvReRt7+NAGHOciMwSkXXeP/MLA2Tc93v/fq8SkddEJLypjVtE/iUi+0RkVY15pxyjiDzs/WxbLyJXnu37BUQRiEgQMA0YBnQBbhSRLs6m8osq4AFVPQ/oB9ztHedUYIGqdgAWeB83NfcBa2s8DoQx/wWYp6qdgZ54xt+kxy0iacC9QLaqdgOCgHE0vXG/AAw9YV6tY/T+Gx8HdPW+5m/ez7w6C4giAPoAm1R1i6pWADOAkQ5n8jlV3a2qy7w/H8bzwZCGZ6wvehd7EbjWkYB+IiLpwAjgnzVmN/UxNwMGAc8BqGqFqhbTxMftFQxEiEgwEAnsoomNW1U/BQ6cMPtUYxwJzFDVclXdCmzC85lXZ4FSBGlAfo3HBd55TZaItAF6AV8BLVV1N3jKAmjhYDR/+DPwE8BdY15TH3NboBB43rtL7J8iEkUTH7eq7gT+AOwAdgMlqvo+TXzcXqca4zl/vgVKEUgt85rscbMiEg3MBn6kqoeczuNPInIVsE9Vc53OUs+CgfOBZ1S1F3CExr875Iy8+8VHAplAKhAlIjc7m8px5/z5FihFUABk1HicjmdzsskRkRA8JfCKqr7hnb1XRFK8z6cA+5zK5wcDgGtEZBueXX6XisjLNO0xg+fvdIGqfuV9PAtPMTT1cV8ObFXVQlWtBN4A+tP0xw2nHuM5f74FShEsBTqISKaIhOL5YmWuw5l8TkQEzz7jtar6VI2n5gK3en++FXirvrP5i6o+rKrpqtoGz5/rR6p6M014zACqugfIF5FO3lmXAWto4uPGs0uon4hEev++X4bnu7CmPm449RjnAuNEJExEMoEOwJKzWrOqBsQEDAc2AJuBnzmdx09jvAjPJuEKIM87DQcS8BxlsNH7a3Ons/pp/IOBt70/N/kxA1lAjvfP+00gPkDG/StgHbAKeAkIa2rjBl7D8x1IJZ7/8X/vdGMEfub9bFsPDDvb97NLTBhjTIALlF1DxhhjTsGKwBhjApwVgTHGBDgrAmOMCXBWBMYYE+CsCIypRyIy+H9XSDWmobAiMMaYAGdFYEwtRORmEVkiInki8nfv/Q5KReSPIrJMRBaISJJ32SwR+VJEVojInP9dJ15E2ovIhyKy3Puadt7VR9e4j8Ar3jNkjXGMFYExJxCR84CxwABVzQKqgZuAKGCZqp4PfAL8wvuSfwMPqWoPYGWN+a8A01S1J57r4ez2zu8F/AjPvTHa4rlekjGOCXY6gDEN0GXABcBS73/WI/Bc4MsNzPQu8zLwhojEAnGq+ol3/ovAf0QkBkhT1TkAqloG4F3fElUt8D7OA9oAi/w+KmNOwYrAmJMJ8KKqPvytmSKPnrDc6a7PcrrdPeU1fq7G/h0ah9muIWNOtgAYJSIt4Pi9Ylvj+fcyyrvMeGCRqpYAB0VkoHf+LcAn6rkPRIGIXOtdR5iIRNbnIIypK/ufiDEnUNU1IvII8L6IuPBcAfJuPDd/6SoiuUAJnu8RwHNJ4OneD/otwG3e+bcAfxeRx7zrGF2PwzCmzuzqo8bUkYiUqmq00zmM8TXbNWSMMQHOtgiMMSbA2RaBMcYEOCsCY4wJcFYExhgT4KwIjDEmwFkRGGNMgPv/TEouTwclSlMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense      # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers        # 케라스의 옵티마이저를 임포트\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np # Numpy를 임포트\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, \n",
    "test_size=0.2, random_state=42)\n",
    "\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(x_train)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(layer)\n",
    "model.add(Dense(20, input_dim=30, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "SGD=optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=SGD ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
